{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mediapipe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcvzone\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mHandTrackingModule\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HandDetector\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\abhin\\Desktop\\.venv\\Lib\\site-packages\\cvzone\\HandTrackingModule.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mHandDetector\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    Finds Hands using the mediapipe library. Exports the landmarks\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    in pixel format. Adds extra functionalities like finding how\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m    many fingers are up or the distance between two fingers. Also\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m    provides bounding box info of the hand found.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mediapipe'"
     ]
    }
   ],
   "source": [
    "from cvzone.HandTrackingModule import HandDetector\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "width, height = 1280, 720\n",
    "gestureThreshold = 300\n",
    "folderPath = r\"C:\\Users\\abhin\\Desktop\\computer_vision\\hand_gesture_controled_presentation\\presentation\"\n",
    "\n",
    "# Camera Setup\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, width)\n",
    "cap.set(4, height)\n",
    "\n",
    "# Hand Detector\n",
    "detectorHand = HandDetector(detectionCon=0.8, maxHands=1)\n",
    "\n",
    "# Variables\n",
    "imgList = []\n",
    "delay = 30\n",
    "buttonPressed = False\n",
    "counter = 0\n",
    "drawMode = False\n",
    "imgNumber = 0\n",
    "delayCounter = 0\n",
    "annotations = [[]]\n",
    "annotationNumber = -1\n",
    "annotationStart = False\n",
    "hs, ws = int(120 * 1), int(213 * 1)  # width and height of small image\n",
    "\n",
    "# Get list of presentation images\n",
    "pathImages = sorted(os.listdir(folderPath), key=len)\n",
    "print(pathImages)\n",
    "\n",
    "while True:\n",
    "    # Get image frame\n",
    "    success, img = cap.read()\n",
    "    img = cv2.flip(img, 1)\n",
    "    pathFullImage = os.path.join(folderPath, pathImages[imgNumber])\n",
    "    imgCurrent = cv2.imread(pathFullImage)\n",
    "\n",
    "    # Find the hand and its landmarks\n",
    "    hands, img = detectorHand.findHands(img)  # with draw\n",
    "    # Draw Gesture Threshold line\n",
    "    cv2.line(img, (0, gestureThreshold), (width, gestureThreshold), (0, 255, 0), 10)\n",
    "\n",
    "    if hands and buttonPressed is False:  # If hand is detected\n",
    "\n",
    "        hand = hands[0]\n",
    "        cx, cy = hand[\"center\"]\n",
    "        lmList = hand[\"lmList\"]  # List of 21 Landmark points\n",
    "        fingers = detectorHand.fingersUp(hand)  # List of which fingers are up\n",
    "\n",
    "        # Constrain values for easier drawing\n",
    "        xVal = int(np.interp(lmList[8][0], [width // 2, width], [0, width]))\n",
    "        yVal = int(np.interp(lmList[8][1], [150, height-150], [0, height]))\n",
    "        indexFinger = xVal, yVal\n",
    "\n",
    "        if cy <= gestureThreshold:  # If hand is at the height of the face\n",
    "            if fingers == [1, 0, 0, 0, 0]:\n",
    "                print(\"Left\")\n",
    "                buttonPressed = True\n",
    "                if imgNumber > 0:\n",
    "                    imgNumber -= 1\n",
    "                    annotations = [[]]\n",
    "                    annotationNumber = -1\n",
    "                    annotationStart = False\n",
    "            if fingers == [0, 0, 0, 0, 1]:\n",
    "                print(\"Right\")\n",
    "                buttonPressed = True\n",
    "                if imgNumber < len(pathImages) - 1:\n",
    "                    imgNumber += 1\n",
    "                    annotations = [[]]\n",
    "                    annotationNumber = -1\n",
    "                    annotationStart = False\n",
    "\n",
    "        if fingers == [0, 1, 1, 0, 0]:\n",
    "            cv2.circle(imgCurrent, indexFinger, 12, (0, 0, 255), cv2.FILLED)\n",
    "\n",
    "        if fingers == [0, 1, 0, 0, 0]:\n",
    "            if annotationStart is False:\n",
    "                annotationStart = True\n",
    "                annotationNumber += 1\n",
    "                annotations.append([])\n",
    "            print(annotationNumber)\n",
    "            annotations[annotationNumber].append(indexFinger)\n",
    "            cv2.circle(imgCurrent, indexFinger, 12, (0, 0, 255), cv2.FILLED)\n",
    "\n",
    "        else:\n",
    "            annotationStart = False\n",
    "\n",
    "        if fingers == [0, 1, 1, 1, 0]:\n",
    "            if annotations:\n",
    "                annotations.pop(-1)\n",
    "                annotationNumber -= 1\n",
    "                buttonPressed = True\n",
    "\n",
    "    else:\n",
    "        annotationStart = False\n",
    "\n",
    "    if buttonPressed:\n",
    "        counter += 1\n",
    "        if counter > delay:\n",
    "            counter = 0\n",
    "            buttonPressed = False\n",
    "\n",
    "    for i, annotation in enumerate(annotations):\n",
    "        for j in range(len(annotation)):\n",
    "            if j != 0:\n",
    "                cv2.line(imgCurrent, annotation[j - 1], annotation[j], (0, 0, 200), 12)\n",
    "\n",
    "    imgSmall = cv2.resize(img, (ws, hs))\n",
    "    h, w, _ = imgCurrent.shape\n",
    "    imgCurrent[0:hs, w - ws: w] = imgSmall\n",
    "\n",
    "    cv2.imshow(\"Slides\", imgCurrent)\n",
    "    cv2.imshow(\"Image\", img)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
